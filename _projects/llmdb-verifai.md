---
layout: page
title: VerifAI
description: VerifAI is designed to verify the correctness of generative AI using multi-modal data lakes.
img: assets/img/verifai.jpg
importance: 2
category: llmdb
related_publications: DBLP:journals/corr/abs-2307-02796
---

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.html path="assets/img/verifai.jpg" title="Verified Generative AI" class="img-fluid rounded z-depth-1" %}
    </div>
</div>


Generative AI has made significant strides, yet concerns about the accuracy and reliability of its outputs continue to grow. Such inaccuracies can have serious consequences such as inaccurate decision-making, the spread of false information, privacy violations, legal liabilities, and more. Although efforts to address these
risks are underway, including explainable AI and responsible AI practices such as transparency, privacy protection, bias mitigation, and social and environmental responsibility, misinformation caused by generative AI will remain a significant challenge. 

We propose that verifying the outputs of generative AI from a data management
perspective is an emerging issue for generative AI. This involves analyzing the underlying data from multi-modal data lakes, including text files, tables, and knowledge graphs, and assessing its quality and consistency. By doing so, we can establish a stronger foundation for evaluating the outputs of generative AI models. 

Such an approach can ensure the correctness of generative AI, promote transparency, and enable decision-making with greater confidence. Our vision is to promote the development of verifiable generative AI and contribute to a more trustworthy and responsible use of AI.