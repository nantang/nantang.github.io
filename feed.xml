<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://nantang.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://nantang.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-07-07T04:03:48+00:00</updated><id>https://nantang.github.io/feed.xml</id><title type="html">blank</title><subtitle>Nan Tang&apos;s research. </subtitle><entry><title type="html">Ph.D. Application Process</title><link href="https://nantang.github.io/blog/2023/phd.positions/" rel="alternate" type="text/html" title="Ph.D. Application Process"/><published>2023-11-02T16:40:16+00:00</published><updated>2023-11-02T16:40:16+00:00</updated><id>https://nantang.github.io/blog/2023/phd.positions</id><content type="html" xml:base="https://nantang.github.io/blog/2023/phd.positions/"><![CDATA[<p>I believe that success in this field is not easy and requires a good professor-student relationship, as well as a common research interest.</p> <h3 id="major-focus-in-the-coming-3-5-years">Major focus in the coming 3-5 years</h3> <p>My research priority for the next 3-5 years will be on building a system for retrieval-based generation and question answering (or data analytics) from multi-modal data lakes, which you can learn more from the Symphony paper (https://www.cidrdb.org/cidr2023/papers/p51-chen.pdf) and its sister system VerifAI (https://arxiv.org/abs/2307.02796) – both are vision papers.</p> <p>It is challenging to index and retrieve data sets from millions (or billions) of data sets with different modalities (tables, images, graphs, tex files) for natural language based data analytical queries Q. Naturally, there are many open problems, such as:</p> <ul> <li> How to index millions of tables, such that given a query Q, we can effectively identify table(s) that can answer Q? </li> <li> How to index millions of tables and text files, such that given a query Q, we can effectively identify text file(s) and table(s) that can answer Q? Moreover, shall we do it in one shot or through iterative retrieval? </li> <li> Can we index thousands of news (image + text) such that we can ask questions such as in how many different NBA players that Obama has played basketball with, and who they are? </li> <li> Ultimately, we want to index all multi-modal data in one system, and use these data to answer any given natural language questions. You can image this is a data lake, with databases, PDF files, excel sheets, emails, and so on, owned by any large corporation. </li> <li> This is hard for both the index part (for example, how to encode different modality of data and align their encodings), and the retrieval part (for example, for each iterative search, we may get more context that may help the next round of retrieval, how to do this and when to terminate? </li> </ul> <p><strong> I have given some hints about research directions. Please try to identify concrete research problems. It is encouraged that you can define the problem based on your background. For example, if you are from the database or NLP background, you may consider “table + text” problems; and if you are from computer vision background, you can consider “image + text” problems. This is to test whether you can identify important problems that combines LLMs and multi-modal data lakes. </strong></p> <h3 id="other-research-interests">Other research interests</h3> <p>I will keep working on the following directions:</p> <ul> <li> Data-centric AI </li> <li> AI-powered data preparation </li> <li> LLM-powered data visualization and augmented reality </li> </ul> <p><strong> If you would like to propose ideas on the above directions, please read my papers on these topics firsts, and make sure I can understand and guide you on your proposal. In other words, if you propose something that is out of my scope of knowledge and ability, I cannot help even if it is good. </strong></p> <h3 id="application-process">Application Process</h3> <p>Unless you have a very strong publication record or a very strong recommendation letter, all applicants will follow the below process:</p> <ol> <li> Send me your CV, transcripts and contacts for reference letters. <em> Note: these letters must be confidential that are sent directly to me from your referees. </em> </li> <li> If you are shortlisted, I will schedule an interview with you. During the interview, please prepare slides to present your background, expertise, and representative research or internship projects. Next step in the interview is to prepare your thoughts or your proposed ideas in the above directions, either my main focus or other research interests. </li> <li> If the proposed ideas are sound and innovative, I would require each applicant to work on it for ~3 months, either remotely or doing an internship at HKUST (GZ). The main purpose is see whether you like the project and research style. </li> <li> I will recruit 2-3 PhDs each year from the above candidates. I will send offers in no later than the end of February. </li> </ol> <p>My allocated time for meeting Ph.D. applications/candidates is 3-5pm, every Monday. If this is your first time interview, please book two consecutive time slots, i.e, for one hour. If this is for a periodical discussion, please book only one time slot, i.e., for 30 minutes.</p> <div class="calendly-inline-widget" data-url="https://calendly.com/nantang-gz/phd-interviews-discussions" style="min-width:320px;height:700px;"></div> <script type="text/javascript" src="https://assets.calendly.com/assets/external/widget.js" async=""></script> ]]></content><author><name></name></author><category term="blockquotes"/><category term="position"/><summary type="html"><![CDATA[Application guidlines for my Ph.D. students]]></summary></entry><entry><title type="html">Red Bird 2023 Project</title><link href="https://nantang.github.io/blog/2023/red-bird-project/" rel="alternate" type="text/html" title="Red Bird 2023 Project"/><published>2023-11-01T16:40:16+00:00</published><updated>2023-11-01T16:40:16+00:00</updated><id>https://nantang.github.io/blog/2023/red-bird-project</id><content type="html" xml:base="https://nantang.github.io/blog/2023/red-bird-project/"><![CDATA[<h3 id="title-data-analytics-over-multi-modal-data-lakes-using-large-language-models">Title: Data Analytics over Multi-modal Data Lakes using Large Language Models</h3> <h3 id="基于大语言模型和多模态数据湖的数据分析">基于大语言模型和多模态数据湖的数据分析</h3> <p>It has three main components:</p> <h3 id="1-improving-large-language-models-llms-through-fine-tuning">1. Improving large language models (LLMs) through fine-tuning</h3> <p>A common problem for LLMs to be used on industrial applications is that these LLMs are simply not good enough. Although many companies have a lot of data assets, however, it is common that after fine-tuning using these data assets, the LLMs are still not good enough. There are multiple reasons:</p> <ul> <li>Data is not good</li> <li>Data is not enough</li> <li>How to best fine-tune LLMs for certain data types are still unknown, such as table learning or knowledge graph learning</li> </ul> <p>Moreover, we do have specific applications to work on:</p> <ul> <li>LLMs for creative educations, especially machine learning courses. <strong> Please contact Prof. Wei Wang (weiwcs@hkust-gz.edu.cn) if you are interested in this thread. </strong> </li> <li>LLMs for database problems, such as NL2SQL</li> <li>LLMs for table learning</li> </ul> <hr/> <h3 id="2-retrieval-augmented-generation">2. Retrieval-augmented generation</h3> <p>For data analytics using multi-modal data lakes, including text files, tables, relational databases, knowledge graphs, it is not reliable to use LLMs to directly give answers. A more reliable way is to first retrieve the datasets that are needed to answer a given query or doing a certain data analytics, and then use LLMs or other existing tools (such as databases) to do the reasoning.</p> <p>So far, how to index text files are widely studied and used, but how to index (large) tables or graphs are still an open problem. Hence, there are many open problems about given a natural language, retrieving:</p> <ul> <li>text file(s)</li> <li>table(s)</li> <li>graph(s)</li> <li>image(s)</li> <li>or a combination of the above files</li> </ul> <p>and then doing the reasoning.</p> <p>Please refer to the Symphony paper (https://www.cidrdb.org/cidr2023/papers/p51-chen.pdf) for a vision on this thread.</p> <p>I envision that <strong>retrieving required multi-modal datasets for a given natural language query</strong> will be the bottleneck that many commercial applications of LLMs for data analytics cannot be grounded.</p> <h3 id="3-data-analytics-over-multi-modal-data-using-llms">3. Data analytics over multi-modal data using LLMs</h3> <p>This is more from the application side, where the required datasets are provided (for example, from the above retrieval exercise). There are multiple directions we are pursuing:</p> <ul> <li>Multi-modal IoT data analytics. <strong> Please contact Prof. Kaishun Wu (wuks@hkust-gz.edu.cn) if you are interested in this thread. </strong></li> <li>LLM powered data visualizations/stories/videos <strong> Please contact Prof. Yuyu Luo (yuyuluo@hkust-gz.edu.cn) if you are interested in this thread. </strong> </li> <li>H.A.R.V.I.S (HKUST AR for VIS): This is a LLM and AR powered system for data visualization</li> </ul> ]]></content><author><name></name></author><category term="blockquotes"/><category term="project"/><summary type="html"><![CDATA[Data Analytics over Multi-modal Data Lakes using Large Language Models]]></summary></entry></feed>